h1. Data Acquisition

This set of recipes will show you the various ways in which you can load data
into Ruport so that you can use its manipulation and formatting tools.

These are meant to cover the basics, for more complex needs, see the section on
Extension Techniques.
<br><br>

h2. Loading CSVs

<hr>

In work, I pretty much munge CSVs day in and day out.  It was indeed the
original reason why I created Ruport.  This recipe will show you some of the
common CSV procedures that I've been using.

h3. Basic Functionality

Ruby's built-in CSV support isn't that bad.  If you just wanted to pull in a
CSV and do some basic manipulations on it, it may be more than enough
for your needs.

Here's a small example of the minimal CSV code you might encounter:
<pre><code>
  require "csv"
  res = CSV.read "foo.csv"
</code></pre>

This would load the contents of "foo.csv" into a two dimensional array.
The tools available to you in Ruby's Array class are extensive, but if you're
like me you get tired of writing the same annoying code to do simple things like
drop the third column.

Typically, this is the way I'd do that in pure ruby:

<pre><code>
  res.map! { |r| r.delete_at(2) }
</pre></code>

Now this isn't really super duper ugly, but when it gets thrown in the mix with
other manipulations, you start to wish the code read very explicitly.  Also, a
ton of maps seems to violate DRY after a while, even if you are doing different
manipulations each time.

So here is the equivalant Ruport code that would load in a CSV and drop the
third column:

<pre><code>
  require "ruport"

  a = Ruport::Data::Table.load("foo.csv")
  a.remove_column(2)
</code></pre>

This kind of syntactic sugar isn't all the functionality you'll get out of using
Ruport to load CSVs, but it sure is sweet :)

h3. Access By Field Names

Ruport automatically takes the first row of your CSV and uses it to define field
names.  This means you can access your data by field name as well as ordinal
position.

So for example, have a look at the CSV below.

<pre><code>
  foo,bar,baz
  1,2,3
  4,5,6
</pre></code>

Once loaded into a Data::Table, <code>my_loaded_data["bar"]</code>, 
<code>my_loaded_data.bar</code> and <code>my_loaded_data[1]</code> become equivalent.

If you have CSV data that does not have field names, you can tell Ruport not to
look for them like this:

<pre><code>
a = Ruport::Data::Table.load("foo.csv", :has_names => false)
</pre></code>

h3. Dealing With Big Files

Ruport doesn't use the standard library's CSV processing library, but instead uses
James Edward Gray II's fine FasterCSV library (http://fastercsv.rubyforge.org)

This library is over 8 times faster than the standard CSV lib, which means that
even though your results are converted into Data::Table, you will see a much smaller
performance hit than if Ruport used the standard library beneath it.

Sometimes when dealing with very big CSVs, it's necessary to do row by row
processing for performance reasons.  This makes it possible to create DataRows
for only the data you're actually interested in.

Below is a snippet of row by row processing for Data::Table creation from CSV.  The
block yields two objects, the first is the Data::Table which will represent your
data, and the second is an array representing the current row.  This is useful
for inspecting the Arrays to see if you're interested in the data before
generating a DataRow for them.  The snippet below will create a Data::Table which
consists of just rows in which the first column is an even number.

<pre><code>
  require "ruport"

  a = Ruport::Data::Table.load("foo.csv") do |s,r|
    s << r if (r[0].to_i % 2).zero?
  end
</code></pre>

So, this about sums up all of Ruport's CSV loading capabilities.  If you see
anything missing that you'd like to see included in Ruport, let me know.

h3. Loading CSVs in the Report DSL

If you are using the Report DSL, there is a shortcut for loading CSVs.

The example below shows a CSV being loaded and converted to PDF

<pre><code>
  require "ruport"

  class MyReport < Ruport::Report
    generate { load_csv("foo.csv").to_pdf }
  end

  MyReport.run { |r| puts r.results }
</code></pre>

h2. Talking to SQL Databases

<hr>

Most reporting jobs involve querying one or more databases.  Ruport provides a
high level interface on top of Ruby DBI to help make getting results from a SQL
database easier.  DBI allows Ruport to talk to many popular database systems, 
including MySQL, Postgres, SQLite, and Oracle.  Personally, I use MySQL for
developing and testing Ruport's SQL functionality, and I have implemented a
number of applications which run against MS SQL Server via ODBC. These recipes
will be based on MySQL because this is the most well tested platform Ruport
supports.  However, these examples should work with minimal modifications on
most database systems DBI supports.

h3. Configuration 

Ruport allows for a number of different database configurations to be used
concurrently.  This is made easy through a simple configuration system.  If you
wanted to connect to the mysql test database using the root user and no password, the
config would look something like this:

<pre><code>
  Ruport.configure { |c|                                                         
    c.source :default, :dsn => "dbi:mysql:test", :user => "root"               
  } 
</code></pre>

The <code>:dsn</code> attribute is a Ruby DBI DSN, and should work as expecting
for whatever DBD you are using.  These are often in the form
<code>dbi:my_dbd_name:my_database_name:my_host_name</code>, though certain DBDs
have special forms, so you should consult the Ruby DBI documentation if you have
trouble.

Ruport's Query class will look for the default source if you do not specify a
source, but it is very easy to tell it to access other sources, so feel free to
define as many as you'd like.

Below is an example of loading a database via ODBC as the default, and a MySQL
database as <code>:test</code>.  We will show later how to select particular
databases when you do your queries.

<pre><code>
  Ruport.configure { |c|
    c.source :default, :dsn => "dbi:odbc:clyde", 
                       :user => "blinky", :password => "123"
    c.source :test,    :dsn => "dbi:mysql:test", :user => "root"
  }
</code></pre>

h3. Basic Functionality

The basic SQL capabilities of Ruport are very similar to DBI, except at a higher
level.  One thing that Ruport can handle that DBI cannot is multi-statement SQL
strings, which is important for loading things such as database dumps.  Another
feature of Ruport's query model is that it supports treating result sets as if
they were regular enumerable objects, which can be very useful.

The general use case will be to generate a Data::Table from a SQL query's results.
This can then be used in all the ways a regular Ruport Data::Table can be used. This
is quite easy to do.

Assuming you already have a default source set, the example below shows how to
run a trivial query and get back a Data::Table.

<pre><code>
  my_data = Ruport::Query.new("select * from foo").result
</code></pre>

Sometimes you might want to load a complex query fom a file.  Ruport's query
model allows this simply by setting the <code>:origin</code>

<pre><code>
  my_data = Ruport::Query.new("some_sql_file.sql",:origin => :file).result
</code></pre>

You can also treat queries as enumerable objects, which will yield Data::Record 
objects by default.

The bit of code below will return an array of the values for "some_field" in
each row of the result set.

<pre><code>
  Ruport::Query.new("select * from foo").map { |r| r["some_field"] }
</pre></code>
 
Note that by default, these query objects will run the query each time either an
Enumerable method or result/execute is called.

If you want to tie the query object to a certain data set temporarily, you can
use caching, which will be explained later.

h3. Selecting sources

The Query object will try to use the :default source specified either in
Ruport::Config or via Ruport.configure when you do your queries.

However, sometimes you might want to use the same query for different sources.
Recall before that we had created a source called :test in the
exact same manner as the :default source.

To build a Query object that will use this :test source, we simply
specify a keyword:

<pre><code>

  a = Ruport::Query.new("select * from foo",:source => :test)

</pre></code>

If we wanted to swap sources midstream, we can easily do that.  The code below
sets the source back to :default.

<pre><code>

  a.select_source :default

</pre></code>

Finally, if we didn't want to use Ruport's configuration system, we can specify
a DSN and username / password directly.

<pre><code>

  b = Ruport::Query.new("select * from foo",:dsn => "dbi:mysql:my_db", 
                                            :user => "root", :password => "cat")
</pre></code>

h3. Caching

Ruport's Query object has simple caching capabilities which may come in handy if
you want to speed up access to the same result set to be used in a number of
ways.  Think of a cached query object as a sort of 'data table generator'.

When caching is enabled, the next set of data which is loaded through the query
object will be stored, and this set of data will be returned to you for each
subsequent method you call on the query object, until you turn caching off.

The following bit of code creates a Query object and enables caching:

<pre><code>
  q = Ruport::Query.new("select * from foo", :cache_enabled => true)
</pre></code>

Now, the first time we run our query, this will load our data which will stick
there until we clear the cache or disable caching.

So you can feel free to use Query as you normally would, but the query will only
be run once.  From here, there are a few more things to note about caching.

If you want to clear out the cache so that the next method called on the object
will grab new data:

<pre><code>
  q.clear_cache
</pre></code>

However, if you want to immediately update your cached data with fresh results:

<pre><code>
  q.update_cache
</pre></code>

Which of the two you use depends on what you are doing, but the key thing to
remember is that <code>clear_cache</code> will simply empty out the cache, it
will not update the data until you run a method that tries to pull the results.
On the other hand <code>update_cache</code> will immediately update your result
set.

You can easily disable caching when you are done with it.  Note that this will
flush the cached data.

<pre><code>
  q.disable_caching
</pre></code>

Likewise, turning it back on is an easy operation as well:

<pre><code>
  q.enable_caching
</pre></code>

Honestly, I have not made much use of this caching capability, but it seems as
if it could come in handy for certain scenarios.  If you are using this
functionality for something, and like it, please let me know what you are doing
so I can make a nice recipe for it.  If you hate this idea, also let me know. ;)

h3. Generators

Sometimes, you might want to have an external iterator for a result set.
Perhaps you want to be able to inspect a record, and then do some other
operations, and eventually move on to the next record.

This technically could be done within an <code>each</code> iterator or by
popping values off of a dataset or array, but what if you want to be able to
easily rewind to the beginning of a result set?

This is where a Generator proves to be useful.  Be sure to check out the docs in
the Ruby standard library (ri Generator), but here is a short example of how to grab a
generator from a result set and how to use it.


<pre><code>
  #builds a generator from the result set
  gen = Ruport::Query.new("select * from foo").generator

  #grabs the first row
  row1 = gen.next

  #grabs the second row
  row2 = gen.next

  #rewinds the generator
  gen.rewind
  
</code></pre>

One thing to beware of, if you reach the end of a result set and try to run
<code>Generator#next</code>, an EOFError will be thrown.  To avoid this, you can
do something like this:

<pre><code>
  gen.next if gen.next?
</pre></code>

This will return the row if it is available, otherwise, it will return nil.

h3. Optimizing for Performance

The first thing to note is that SQL will (almost) always be faster than any ruby
manipulations you can do.  This means that for big or tough queries, the best
route to fast results is some good SQL.  Eventually, Ruport will have some sort
of DSL to help you with this, but for now, we trust you to know your SQL. ;)

Assuming you've got some decent SQL, and you still need to optimize performance,
you should probably never, ever try to build a Data::Table with greater 
than 5 or 10k records. This performance issue may be overcome in the future if I
see sufficient need for it in the community, but for now, Data::Table are really not
meant to handle that much data quickly.

Therefore, you will probably want to use row by row operations.  This way you
can quickly throw out data you are uninterested in before you ever stick it in a
Data::Table.

However, you'll also want to strip down the rows to something more lightweight.
DBI::Rows are currently the lightest it gets using Ruport, which when used,
pretty much has the same efficiency as Ruby DBI itself.

The following example shows how you can build a Data::Table using DBI::Rows as the
base and doing some conditional logic that will help lighten the load.

<pre><code>
  
  #create a query object and tell it to yield DBI::Rows by default
  a = Ruport::Query.new("select * from foo",:raw_data => true)
 
  #set up a dataset specifying only the fields I want to capture
  data = Ruport::Data::Table.new :column_names => %w[fields i am interested in]

  #append the data to my set if the "name" field starts with a lowercase 'g'
  a.inject(data) { |s,r|
    s << r if r["name"] =~ /^g/ ; s
  }
</pre></code>

This code attacks efficiency in a lot of ways.  First of all, it throws out any
uninteresting columns, saving space and time.  Secondly, it does a conditional
before you load data into your Data::Table, which is much better than converting all
of the data and then dropping some rows.  Finally, it uses DBI::Rows instead of
DataRows for its iterator, ensuring that a much lighter structure is used for
comparison.

This should result in a hefty performance gain.

However, if you are *really* concerned about speed / size, you're going to want
to roll your own DBI code.  The current implementation of Query is still doing a
fetch_all under the hood, which may be really slow for massive sets.  This will
likely be changed in upcoming versions of Ruport.

However, since it's usually Ruport, and not DBI that is the bottleneck, this
sort of technique will probably be sufficient in most cases where you need a
decent speed boost for medium to fairly large size result sets.

This basically sums up the Query class and its functionality.  I'll be happy to
consider feedback, so please be sure to contact me if you have any needs that
aren't being met or suggestions on how to improve this functionality.

h2. ActiveRecord support

<hr>

Ruby Reports has some basic support for integration with ActiveRecord. Because
we didn't want to reinvent the AR/Rails wheel, the support is basically a
minimal set of tools for working within a Rails app.  Note that although you
can still use Ruport as a normal library throughout Rails, this section will
focus specifically on the features Ruport adds to ActiveRecord through the
acts_as_reportable system.

Ruport's rails support gives you a nice <code>ActiveRecord#to_ds</code> which
allows you to convert a model or a find on a model into a Data::Table.  From there,
you are free to use all of Ruport's data manipulation tools.

It also provides some formatting shortcuts

h3. Enabling acts_as_reportable

In order to get Ruport to talk to Rails, not much needs to be done.  Really,
it's just two special lines of code.  Ruport does not enable Rails support
by default, so you need to turn it on if you want to use it.

To enable the rails features, put <code>require 'ruport/rails'</code> in your
<code>environment.rb</code> file in your rails app.  

If you are using the ActiveRecord support somewhere else, perhaps in Camping,
just put this line wherever you do normal requires.

The next step is to hook up Ruport to whatever models you'd like:

<pre><code>
  class User < ActiveRecord::Base
    acts_as_reportable
  end
</code></pre>

If you want to enable Ruport support in all models, you can do this:

<pre><code>
  class ActiveRecord::Base
    acts_as_reportable
  end
</code></pre>

Be forewarned however, that might be overzealous

h3. Easy Data::Table Conversion

If you've got a relatively small model and you need most of the data from it to
do some reporting, it couldn't get easier to convert it into a Data::Table:

<pre><code>
  User.to_table
</code></pre>

You also can set the columns of the Data::Table here, if you'd like.  

<pre><code>
  User.to_ds :columns => %w[ name email ]
</code></pre>

Note that a lot of times it's useful to wait until formatting your table to
remove various columns.  Many times you end up wanting to do something with
columns you do not plan on displaying.

h3. Using ActiveRecord.find

For dealing with models which wrap a lot of data, sucking the entire table into
a Data::Table would be costly (and most likely painful).

Therefore, you can freely use ActiveRecord's find method on the fly while you
are converting.  To do this, pass whatever options you would pass
ActiveRecord.find via the <tt>:find</tt> keyword:

<pre><code>
  User.to_table :find => { :conditions => [ "name = ?", "greg" ] }
</code></pre>

The find will be executed first and then the results will be converted to a
Data::Table.

h3. Formatting Shortcuts

Ruport will also define a formatted_table method which you might find helpful in
your application helpers.  This is almost equivalent to: 

<pre><code>
  some_data_table.as(:format_type) { |engine| ... } 
</code></pre>

The difference is you can take advantage of AR finds.  Here are some examples
of this feature and how it may be used.

Dump all the users as an HTML table:
<pre><code>
  User.formatted_table :html
</code></pre>

Create a CSV file containing all the records that have an email address
containing 'foo', put in order of the id column:

<pre><code>
  User.formatted_table :csv, 
    :find => { :conditions => "email like '%foo%'", :order => 'id' }
</code></pre>

Create a CSV file containing all the records that have an email address
containing 'foo' using 'with_scope', put in order of the id column:

<pre><code>
  User.with_scope( :find => {:conditions => "email like'%foo%'"}) {
    User.formatted_table :html, :find => { :order => 'id'} 
  }
</code></pre>

Create a CSV file containing all the records that have an email address
containing 'foo', put in order of the id column, display only the id
and email columns:

<pre><code>
  User.formatted_table :csv, :columns => %w[id email], 
    :find => { :conditions => "email like '%foo%'", :order => 'id' }                                      
</code></pre>

Create a PDF file containing all the records that have an email address
containing 'foo', and then send it back to the browser as 
'emails_with_foo.pdf':

<pre><code>
  report = User.formatted_table :pdf, :columns => %w[id email], 
    :find => { :conditions => "email like '%foo%'", :order => 'id' }  

  send_data report, :type => 'application/x-pdf', 
    :disposition => 'inline', :filename => 'emails_with_foo.pdf'
</code></pre>

Keep in mind that your finds are just ActiveRecord finds and the results are
just the same as Ruport's Data::Table and Format.table outputs.  This means you are free
to use the best of both AR and Ruport to accomplish your tasks.
